"use server";

import {
  SummaryGenerationOptions,
  SummaryGenerationParams,
} from "@/types/summary";
import OpenAI from "openai";
import { buildSystemPrompt, buildUserPrompt } from "./buildPrompts";
import {
  defaultModel,
  defaultTimeout,
  estimateCost,
  getDefaultMaxTokens,
} from "./helpers";

/**
 * Call OpenAI API with proper error handling and timeout
 */
export async function callOpenAI(
  params: SummaryGenerationParams,
  options: SummaryGenerationOptions
): Promise<{
  content: string;
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
    estimatedCost?: number;
  };
  notes?: string;
}> {
  const key = process.env.OPENAI_API_KEY as string;

  if (!key) {
    throw new Error("OpenAI API key is not configured");
  }

  const openAi = new OpenAI({ apiKey: key });

  const timeout = options.timeout || defaultTimeout;

  // Create the prompt
  const systemPrompt = buildSystemPrompt(params.summaryType);
  const userPrompt = buildUserPrompt(params);

  // Create the completion with timeout
  const completion = await Promise.race([
    openAi.chat.completions.create({
      model: params.model || defaultModel,
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt },
      ],
      max_tokens: params.maxTokens || getDefaultMaxTokens(params.summaryType),
      temperature: options.temperature || 0.7,
    }),
    new Promise<never>((_, reject) =>
      setTimeout(() => reject(new Error("OpenAI request timeout")), timeout)
    ),
  ]);

  const content = completion.choices[0]?.message?.content;
  if (!content) {
    throw new Error("No content generated by OpenAI");
  }

  // Calculate usage and estimated cost
  const usage = completion.usage
    ? {
        promptTokens: completion.usage.prompt_tokens,
        completionTokens: completion.usage.completion_tokens,
        totalTokens: completion.usage.total_tokens,
        estimatedCost: estimateCost(
          completion.usage.prompt_tokens,
          completion.usage.completion_tokens,
          params.model || defaultModel
        ),
      }
    : undefined;

  return {
    content: content.trim(),
    usage,
    notes: `Generated using ${params.model || defaultModel}`,
  };
}
